# _*_ Coding: utf-8 -*-

# Iterates over the output generated by the Pytorch,
# TensorFlow and TensorFlow.js crawlers and provided a sorted
# output of every function.

import json
import re
from translations import WORD_TRANSLATIONS, COMMAND_TRANSLATIONS

# Compiler() is the main parent class responsible for
# all the translation from the respective output files
# from all the crawlers.


class Compiler(object):
    tf = []  # Create empyt array for TensorFlow.
    tfjs = []  # Create empty array for TensorFlow.js.
    torch = []  # Create empty array for Pytorch.
    # Create dictionary for TensorFlow, TensorFlow.js and Pytorch.
    main_map = {'tf': {}, 'tfjs': {}, 'torch': {}}
    base_defs = set()

    # This constructor calls all our data from tesnorFlow, Tensorflow.js
    # and Pytorch crawler output files and creates instances for further usage.
    def __init__(self):
        with open('./output/tf/2.1.json') as tf_file, \
                open('./output/torch/1.4.0.json') as torch_file, \
                open('./output/tfjs/1.5.1.json') as tfjs_file:
            self.tf = json.load(tf_file)
            self.tfjs = json.load(tfjs_file)
            self.torch = json.load(torch_file)

    # The normalize_func_name() function is a method which takes
    # all the string values under function name from the target
    # file and normalizizes them into header format.
    def normalize_func_name(self, name):
        # Regex rules for compiling a string to a Regex object.
        # Here the rules match on to two types of characters in a string.
        alpha = re.compile(r'[\W][a-zA-Z0-9]*')
        return alpha.sub('', name).lower()

    # The generate_attrs() function is a method which takes all
    # the fucntion calls from the targeted code.
    def generate_attrs(self, code):
        # Regex rules for compiling a string to a Regex object.
        # Here the rules match on to two types of groups in a given code.
        split_def = re.compile(r'^([\w\.]+)\((.*)\)')
        return split_def.match(code)[1].split('.')

    # The populate_command() fucntion arranges all the output
    # that is generated into proper order and with appropriate header name.
    def populate_command(self, lib):
        for f in getattr(self, lib):
            # generates a header for the fucntion under which all the
            # related arguments are placed in the output file.
            nfunc = self.normalize_func_name(f['function_name'])
            # Generates the functiona call for the respective fucntion.
            f['attrs'] = self.generate_attrs(f['code'])
            # Generates all the related arguments to the function.
            f['args'] = self.hydrate_args(f['args'], f['kwargs'])
            # Generates the fucntion name for reference.
            f['name'] = f['function_name']
            del f['kwargs']
            del f['code']
            del f['function_name']
            self.main_map[lib][nfunc] = [f]
            self.base_defs.add(nfunc)

    # The load_base_defs() function itirates through the libraries
    # and generates a normalized output.
    def load_base_defs(self):
        self.populate_command('tf')
        self.populate_command('tfjs')
        self.populate_command('torch')

    # The hydrate_args() fucntion maps the generated list and filters
    # them out with selected arguments according to the operators and
    # stores in variable as a list.
    # These list are divided into list of normal arguments and
    # keyword arguments as ba and bk respectively.
    def hydrate_args(self, base_args, base_kwargs):
        base_args = list(filter(lambda a: a not in ['', '?'], base_args))
        base_kwargs = list(
            filter(lambda a: a[0] not in ['', '?'], base_kwargs)
        )
        # normal arguments
        ba = [
            {
                'name': self.normalize_func_name(a),
                'kwarg': False,
                'opt': a.endswith('?'),
            } for i, a in enumerate(base_args)
        ]
        # keyword arguments
        bk = [
            {
                'name': self.normalize_func_name(a[0]),
                'kwarg': True,
                'opt': True
            } for a in base_kwargs
        ]
        return ba + bk

    # The match_arg_names() fucntion creates a loop that goes through
    # all the fucntion and checks for the order issues between
    # the fucntion considered.
    # For example : There is a fucntion mapping to Pytorch matmul
    # and TensorFlow matmul that may take same arguments but
    # in different order.
    # This fucntion compares the arguments between the two and fixes
    # any issue related to order between the two.
    def match_arg_names(self, from_args, to_args, to_lang):
        for from_arg in from_args:
            try:
                to_arg = next(
                    m for m in to_args if m.get('name') == from_arg.get('name')
                )
                to_name = to_arg.get('name', None)
                if to_name is not None:
                    from_arg[to_lang] = to_name
            except Exception:
                to_name = WORD_TRANSLATIONS[to_lang].get(
                    from_arg['name'], None)
                if to_name is not None:
                    from_arg[to_lang] = to_name
        return from_args

    # The load_translations() method that translates the list
    # generated by all the crawlers with help of word translation.
    def load_translations(self, from_lang):
        langs = ['torch', 'tfjs', 'tf']
        langs.pop(langs.index(from_lang))

        for d in self.base_defs:
            # First perform any word level translations
            from_name = WORD_TRANSLATIONS[from_lang].get(d, False) or d

            # Check if translation exists in our from language
            if from_name not in self.main_map[from_lang]:
                continue

            # TODO: Treat as list
            from_def = self.main_map[from_lang][from_name][0]
            from_args = from_def['args']
            # Check if translatable to other langs
            for to_lang in langs:
                # Perform word level translation for target language
                to_name = WORD_TRANSLATIONS[to_lang].get(d, False) or d
                if to_name not in self.main_map[to_lang]:
                    continue
                # TODO: Treat as list
                to_def = self.main_map[to_lang][to_name][0]
                from_def[to_lang] = to_name

                # Format & match args
                to_args = to_def['args']
                from_def['args'] = self.match_arg_names(
                    from_args,
                    to_args,
                    to_lang
                )

    # The slim_output() fucntion creates dictinoary from the
    # language lists with a labeled header and returns it to
    # the output variable as a list.
    def slim_output(self, from_lang, to_lang):
        input_dict = {
            from_lang: self.main_map[from_lang],
            to_lang: self.main_map[to_lang]
        }
        output = {
            from_lang: {},
            to_lang: {}
        }

        # The hydrate_keys() function generates dictionary from the
        # given input variables by sorting them according to their labels.
        def hydrate_keys(input_dict, output, from_lang, to_lang):
            for k, v in input_dict[from_lang].items():
                # TODO: Treat as list
                v = v[0]
                if v.get(to_lang, '') in input_dict[to_lang]:
                    output[from_lang][k] = [v]
            return output

        output = hydrate_keys(input_dict, output, from_lang, to_lang)
        output = hydrate_keys(input_dict, output, to_lang, from_lang)

        return output

    # The load_manual_translations() function maps the commands for
    # a certain fucntion into a dictioanry with labels for the commands.
    def load_manual_translations(self):
        for lang, commands in COMMAND_TRANSLATIONS.items():
            self.main_map[lang].update(commands)

    # The output_data() function maps all the compressed binareis into
    # a .json file.
    def output_data(self):
        with open('../../pythreepio/static/mapped_commands_full.json', 'w',
                  encoding='utf8') as f:
            # dumps entire compressed data into the file.
            json.dump(self.main_map, f, indent=4, ensure_ascii=False)
        # Compressed map with only torch & tfjs
        torch_tfjs_map = self.slim_output('torch', 'tfjs')
        with open('../../static/mapped_commands_torch_tfjs.json', 'w',
                  encoding='ascii') as f:
            # dumps tfjs and torch compressed data in to json file.
            json.dump(
                torch_tfjs_map,
                f,
                separators=(',', ':'),
                ensure_ascii=False
            )


def main():
    c = Compiler()  # The parent class called as variable
    c.load_base_defs()  # Caches all the functions form the libraries.
    # Creates dictionary from the mapped commands form the libraries.
    c.load_manual_translations()
    c.load_translations('tfjs')  # Generate list for TensorFlow functions.
    c.load_translations('torch')  # Generate list for Torch functions.
    c.load_translations('tf')  # Generate list for TensorFlow.js fucntions.
    c.output_data()  # Dumps all the created lists into the output .json file.A


if __name__ == '__main__':
    main()
